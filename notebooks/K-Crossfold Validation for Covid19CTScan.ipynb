{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ef1257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import jaccard_score\n",
    "import copy\n",
    "\n",
    "sys.path.append(os.path.join('', '../pyunet/lib'))\n",
    "from unet import UNet\n",
    "from loss_functions import dice_loss, tversky_loss\n",
    "\n",
    "device          = 'cuda'\n",
    "in_channels     = 3\n",
    "out_channels    = 4\n",
    "image_dir       = \"./images/covid19ctscan/images\"\n",
    "mask_dir        = \"./images/covid19ctscan/masks\"\n",
    "learning_rate   = 0.0001\n",
    "img_width       = 32\n",
    "img_height      = 32\n",
    "gpu_index       = 0\n",
    "batch_size      = 2\n",
    "dim             = (img_width, img_height)\n",
    "\n",
    "# Experimental configurations\n",
    "experiments = [\n",
    "    { 'loss_type': 'CE', 'is_normalized': True, 'model_file': './models/covid19ctscan-{}-{}-CE-true.pth'.format(img_width, img_height) },\n",
    "    { 'loss_type': 'CE', 'is_normalized': False, 'model_file': './models/covid19ctscan-{}-{}-CE-false.pth'.format(img_width, img_height) },\n",
    "]\n",
    "\n",
    "# Number of partitions\n",
    "k = 10\n",
    "\n",
    "# Number of epochs per training session\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9c8f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, mask_paths, indices, dim):\n",
    "        self.image_paths    = image_paths\n",
    "        self.mask_paths     = mask_paths\n",
    "        self.indices        = indices\n",
    "        self.dim            = dim\n",
    "\n",
    "        self.image_dataset  = []\n",
    "        self.mask_dataset   = []\n",
    "\n",
    "        for i in range(len(indices)):\n",
    "            self.image_dataset.append(self.image_paths[indices[i]])\n",
    "            self.mask_dataset.append(self.mask_paths[indices[i]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = torch.Tensor(\n",
    "            (\n",
    "                cv2.resize(\n",
    "                    cv2.imread(self.image_dataset[index]),\n",
    "                    self.dim\n",
    "                ) / 255\n",
    "            ).transpose((2, 0, 1))\n",
    "        )\n",
    "\n",
    "        y = torch.Tensor(\n",
    "            cv2.resize(\n",
    "                cv2.imread(self.mask_dataset[index], 0),\n",
    "                self.dim\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a043600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(loader, model, optimizer, loss_fn, scaler, device):\n",
    "    loop = tqdm(loader)\n",
    "\n",
    "    ave_loss = 0.0\n",
    "    count = 0\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data    = data.to(device)\n",
    "        targets = targets.long().to(device=device)\n",
    "\n",
    "        # Forward\n",
    "        predictions = model.forward(data)\n",
    "\n",
    "        loss = loss_fn(predictions, targets)\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Update tqdm\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        ave_loss += loss.item()\n",
    "        count += 1\n",
    "\n",
    "    ave_loss = ave_loss / count\n",
    "    \n",
    "    return ave_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f065978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unicodedata import is_normalized\n",
    "\n",
    "\n",
    "scores = []\n",
    "\n",
    "image_paths = list(map(lambda o: os.path.join(image_dir, o), sorted(os.listdir(image_dir))))\n",
    "mask_paths  = list(map(lambda o: os.path.join(mask_dir, o), sorted(os.listdir(mask_dir))))\n",
    "\n",
    "num_items       = len(image_paths)\n",
    "len_partition   = int(num_items / k)\n",
    "\n",
    "print(\"Len Partition: {}\".format(len_partition))\n",
    "\n",
    "indices = list(range(num_items))\n",
    "\n",
    "index = 0\n",
    "\n",
    "aggregated_scores = []\n",
    "\n",
    "for i in range(k):\n",
    "    device = 'cuda'\n",
    "\n",
    "    validation_indices  = np.array(indices[index:index + len_partition])\n",
    "    training_indices    = np.delete(indices, validation_indices)\n",
    "\n",
    "    index = index + len_partition\n",
    "    if device == 'cuda':\n",
    "        print(\"CUDA Device: {}\".format(torch.cuda.get_device_name(gpu_index)))\n",
    "        device = \"cuda:{}\".format(gpu_index)\n",
    "\n",
    "    print(\"Device: {}\".format(device))\n",
    "\n",
    "    # Loop through each experiment\n",
    "    for experiment in experiments:\n",
    "        is_normalized   = experiment.get('is_normalized')\n",
    "        loss_type       = experiment.get('loss_type')\n",
    "        model_file      = experiment.get('model_file')\n",
    "\n",
    "        model = UNet(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            is_normalized=is_normalized\n",
    "        ).to(device)\n",
    "\n",
    "        if loss_type == 'CE':\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "        elif loss_type == 'DL':\n",
    "            loss_fn = dice_loss\n",
    "        elif loss_type == 'TL':\n",
    "            loss_fn = tversky_loss\n",
    "\n",
    "        print(\"K: {} Loss Fn: {} Is Normalized: {} Model File: {}\".format(i+1, loss_type, is_normalized, model_file))\n",
    "        optimizer   = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        scaler      = torch.cuda.amp.GradScaler()\n",
    "\n",
    "        train_ds = CustomDataset(\n",
    "            image_paths=image_paths,\n",
    "            mask_paths=mask_paths,\n",
    "            indices=training_indices,\n",
    "            dim=dim\n",
    "        )\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_ds,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            drop_last=False\n",
    "        )\n",
    "\n",
    "        losses = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            print(\"Epoch: {}\".format(epoch))\n",
    "            ave_loss = train_fn(train_loader, model, optimizer, loss_fn, scaler, device)\n",
    "\n",
    "            print(\"Ave Loss: {}\".format(ave_loss))\n",
    "            print(\"Saving file to {}\".format(model_file))\n",
    "\n",
    "            state = {\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'out_channels': out_channels\n",
    "            }\n",
    "\n",
    "            losses.append(ave_loss)\n",
    "\n",
    "            torch.save(state, model_file)\n",
    "\n",
    "        x_validation = []\n",
    "        y_validation = []\n",
    "\n",
    "        for j in range(len(validation_indices)):\n",
    "            x_validation.append(\n",
    "                cv2.cvtColor(\n",
    "                    cv2.resize(\n",
    "                        cv2.imread(\n",
    "                            image_paths[validation_indices[j]],\n",
    "                            1\n",
    "                        ),\n",
    "                        dim\n",
    "                    ),\n",
    "                    cv2.COLOR_BGR2RGB    \n",
    "                ).transpose((2, 0, 1))\n",
    "            )\n",
    "\n",
    "            y_validation.append(\n",
    "                cv2.resize(\n",
    "                    cv2.imread(\n",
    "                        mask_paths[validation_indices[j]],\n",
    "                        0\n",
    "                    ),\n",
    "                    dim\n",
    "                )\n",
    "            )\n",
    "\n",
    "        x_validation = torch.FloatTensor(np.array(x_validation)).to(device)\n",
    "        y_validation = torch.FloatTensor(np.array(y_validation)).to(device)\n",
    "\n",
    "        predictions = torch.argmax(model.forward(x_validation), 1)\n",
    "\n",
    "        macro_scores = []\n",
    "        label_scores = []\n",
    "\n",
    "        for prediction_index in range(len(x_validation)):\n",
    "            prediction = predictions[prediction_index]\n",
    "\n",
    "            target = y_validation[0]\n",
    "\n",
    "            target = target.detach().cpu().numpy().ravel()\n",
    "            prediction = prediction.detach().cpu().numpy().ravel()\n",
    "\n",
    "            macro_score = jaccard_score(target, prediction, average='macro')\n",
    "            label_score = jaccard_score(target, prediction, average=None)\n",
    "\n",
    "            print(label_score)\n",
    "\n",
    "            macro_scores.append(macro_score)\n",
    "            label_scores.append(copy.deepcopy(label_score))\n",
    "\n",
    "        scores.append({\n",
    "            'k': i+1,\n",
    "            'experiment': experiment,\n",
    "            'macro_scores': macro_scores,\n",
    "            'label_scores': copy.deepcopy(label_scores),\n",
    "            'losses': copy.deepcopy(losses),\n",
    "            'ave_macro_score': sum(macro_scores) / len(macro_scores)\n",
    "        })\n",
    "\n",
    "    aggregated_scores.append(copy.deepcopy(scores))\n",
    "\n",
    "#    print(\"Validation Indices\")\n",
    "#    print(validation_indices)\n",
    "#\n",
    "#    print(\"Training Indices\")\n",
    "#    print(training_indices)\n",
    "#\n",
    "#    print(\"================================\")\n",
    "#    validation_image_paths = image_paths[index:index + len_partition]\n",
    "#    validation_mask_paths = mask_paths[index:index + len_partition]\n",
    "#\n",
    "#    print(\"Validation Image Paths:\")\n",
    "#    print(validation_image_paths)\n",
    "#\n",
    "#    print(\"Validation Mask Paths:\")\n",
    "#    print(validation_mask_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3da31df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save json\n",
    "import codecs, json\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "aggregated_scores = np.array(aggregated_scores).tolist()\n",
    "file_path = './aggregate_scores.json'\n",
    "\n",
    "json.dump(aggregated_scores, codecs.open(file_path, 'w', encoding='utf-8'),\n",
    "    separators=(',', ':'),\n",
    "    sort_keys=True,\n",
    "    indent=2,\n",
    "    cls=NpEncoder)\n",
    "\n",
    "aggregated_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
